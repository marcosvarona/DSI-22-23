# Errores en los datos a evitar

Basado en el documento de [Geckoboard](https://www.geckoboard.com/assets/img/data_fallacies/Geckoboard-Data-Fallacies-Poster.pdf), le√≠do adem√°s en [KDNuggets](https://www.kdnuggets.com/2017/12/4-common-data-fallacies.html) y con un [üì∫ tambi√©n](https://www.youtube.com/watch?v=ebEkn-BiW5k)

|||ADE|Ingenier√≠a
-|-|-|-|
Cosecha selectiva (Cherry Picking)|Seleccionar resultados que se ajustan a tu afirmaci√≥n y excluir aquellos que no lo hacen.|Un CEO de una empresa de tecnolog√≠a selecciona solo los datos financieros positivos de su compa√±√≠a para presentarlos a los inversores, omitiendo las m√©tricas negativas.|Un ingeniero selecciona solo los datos de resistencia de los materiales que cumplen con las especificaciones, mientras ignora los datos que no cumplen con ellas, lo que puede llevar a una mala evaluaci√≥n de la calidad del material.
Extracci√≥n de datos (Data Dredging)|Probar repetidamente nuevas hip√≥tesis contra el mismo conjunto de datos, sin reconocer que la mayor√≠a de las correlaciones ser√°n resultado del azar.|
Sesgo de supervivencia (Survivorship Bias)|Sacar conclusiones de un conjunto incompleto de datos, porque esos datos han "sobrevivido" a ciertos criterios de selecci√≥n.|Un inversor estudia solo las empresas que sobreviven en el mercado, ignorando aquellas que fracasaron, lo que puede llevar a una evaluaci√≥n incorrecta del riesgo y la rentabilidad.|Un ingeniero estudia solo los dise√±os que fueron exitosos, ignorando los dise√±os que fracasaron, lo que puede llevar a una evaluaci√≥n inadecuada de la fiabilidad y seguridad de los dise√±os.
Efecto cobra|Establecer un incentivo que produce accidentalmente el resultado opuesto al que se pretend√≠a. Tambi√©n conocido como incentivo perverso.|Una empresa decide establecer un programa de incentivos basado en la cantidad de ventas de un determinado producto. Si los incentivos son mal dise√±ados y no tienen en cuenta otros factores relevantes, los vendedores pueden comenzar a enfocarse √∫nicamente en el producto con incentivos, descuidando otros productos importantes y perjudicando a la empresa a largo plazo.|Un equipo de desarrollo de software que se fija una fecha l√≠mite muy estricta para el lanzamiento de un producto. Si el equipo se enfoca demasiado en cumplir con la fecha l√≠mite, podr√≠an descuidar la calidad del software y lanzar un producto con errores y problemas de seguridad, lo que en √∫ltima instancia da√±ar√≠a la reputaci√≥n de la empresa y afectar√≠a su rentabilidad a largo plazo.|
Causalidad falsa|Asumir err√≥neamente que cuando dos eventos parecen estar relacionados, uno debe haber causado el otro.|Una empresa experimenta un aumento en sus ventas despu√©s de lanzar una campa√±a publicitaria en redes sociales y concluye que la campa√±a fue la √∫nica causa del aumento en las ventas, ignorando otros factores que podr√≠an haber influido, como cambios en la demanda del mercado.|En un proyecto de desarrollo de software, se decide utilizar una nueva tecnolog√≠a de base de datos y se observa una mejora en el rendimiento del sistema despu√©s de su implementaci√≥n. Sin embargo, se ignora el hecho de que otras mejoras en el c√≥digo del software tambi√©n pueden haber contribuido al aumento del rendimiento, y se concluye que la nueva tecnolog√≠a de base de datos fue la √∫nica causa del aumento.|
Manipulaci√≥n electoral|Manipular los l√≠mites geogr√°ficos utilizados para agrupar datos con el fin de cambiar el resultado.
Sesgo de muestreo|Sacar conclusiones de un conjunto de datos que no es representativo de la poblaci√≥n que se est√° intentando entender.|Si una empresa realiza una encuesta sobre la satisfacci√≥n del cliente y solo pregunta a los clientes que han tenido una experiencia positiva con la empresa, la muestra resultante puede ser sesgada hacia los clientes satisfechos, lo que lleva a una visi√≥n incompleta de la satisfacci√≥n general del cliente.|Una empresa de tecnolog√≠a que solo contrata a graduados de universidades de √©lite para sus trabajos de ingenier√≠a puede estar sesgada en su selecci√≥n de candidatos y, por lo tanto, puede perder a personas altamente talentosas que no asistieron a esas universidades de √©lite.|
Falacia del jugador|Creer err√≥neamente que, debido a que algo ha sucedido con m√°s frecuencia de lo habitual, es menos probable que suceda en el futuro (y viceversa).|Una empresa invierte en una nueva tecnolog√≠a porque ha tenido √©xito en el pasado. Sin embargo, el √©xito pasado no garantiza el √©xito futuro, y la empresa podr√≠a estar cometiendo la falacia del jugador al pensar que la nueva tecnolog√≠a ser√° exitosa solo porque sus tecnolog√≠as anteriores lo fueron.|Un equipo de desarrollo que cree que un software o sistema seguir√° funcionando correctamente, incluso despu√©s de haber encontrado varios errores o fallos en versiones anteriores. Esta creencia puede llevar a una complacencia en la calidad del c√≥digo y puede resultar en un sistema defectuoso.|
Efecto Hawthorne|El acto de monitorear a alguien puede afectar su comportamiento, lo que lleva a resultados falsos. Tambi√©n conocido como el efecto del observador.|Un gerente de producci√≥n decide realizar un experimento para medir la productividad de sus trabajadores. Durante un mes, coloca a un equipo de trabajo en una nueva l√≠nea de producci√≥n con un ambiente mejorado y monitorea su productividad. Sin embargo, los trabajadores notan la atenci√≥n extra y comienzan a trabajar m√°s duro de lo normal, lo que lleva a una mejora en la productividad. Al final del mes, el gerente concluye que la nueva l√≠nea de producci√≥n y el ambiente mejorado son la causa del aumento en la productividad, sin reconocer el efecto Hawthorne de la atenci√≥n extra.|Un ingeniero de software est√° probando una nueva funci√≥n en un programa y quiere medir la eficacia de la misma. Sin embargo, cuando se realiza la prueba, los usuarios del programa est√°n m√°s conscientes y m√°s comprometidos en proporcionar retroalimentaci√≥n. Debido a esto, la funci√≥n parece ser m√°s eficaz de lo que realmente es, y el ingeniero concluye err√≥neamente que la funci√≥n es exitosa en t√©rminos de satisfacci√≥n del usuario, sin reconocer el efecto Hawthorne de la atenci√≥n extra.|
Regresi√≥n hacia la media|Cuando algo sucede de manera inusualmente buena o mala, volver√° a la media con el tiempo.|Un gerente de ventas observa que un vendedor ha tenido un mes excepcionalmente bueno en t√©rminos de ventas y decide darle un bono adicional para recompensarlo. Sin embargo, el mes siguiente las ventas del vendedor vuelven a ser m√°s cercanas al promedio. Si el gerente esperaba que las ventas del vendedor fueran siempre excepcionales, podr√≠a haber ca√≠do en la falacia de regresi√≥n hacia la media.|Un equipo de ingenieros de software analiza el rendimiento de un algoritmo de clasificaci√≥n de im√°genes en un conjunto de datos de prueba y descubre que el algoritmo tiene una precisi√≥n del 100%. Los ingenieros deciden implementar el algoritmo en producci√≥n, pero descubren que su precisi√≥n disminuye significativamente en comparaci√≥n con el conjunto de prueba. Este resultado podr√≠a ser un ejemplo de regresi√≥n hacia la media, ya que la precisi√≥n del conjunto de prueba era probablemente excepcionalmente alta debido a la selecci√≥n de datos y no reflejaba el rendimiento real del algoritmo.|
Paradoja de Simpson|Cuando aparece una tendencia en diferentes subconjuntos de datos, pero desaparece o se invierte cuando los grupos se combinan.|Supongamos que una empresa est√° interesada en evaluar el rendimiento de sus vendedores en dos regiones diferentes. Al analizar los datos, se observa que en cada regi√≥n, los vendedores que trabajan a tiempo completo venden m√°s que los que trabajan a tiempo parcial. Sin embargo, al combinar los datos de ambas regiones, se descubre que los vendedores a tiempo parcial, en realidad, venden m√°s que los de tiempo completo en general. Esta paradoja se produce porque la regi√≥n con m√°s vendedores a tiempo parcial ten√≠a una demanda mayor de productos que la otra regi√≥n.|Se est√° desarrollando un algoritmo de clasificaci√≥n para reconocer caracteres escritos a mano en im√°genes digitales. En una primera prueba, el algoritmo tiene un alto porcentaje de √©xito al clasificar los caracteres de un conjunto de entrenamiento. Sin embargo, al probarlo con un conjunto de prueba diferente, el porcentaje de √©xito se reduce dr√°sticamente. Esto puede deberse a que el algoritmo se ha ajustado demasiado a los datos de entrenamiento, perdiendo su capacidad para clasificar correctamente los datos de prueba. En este caso, la paradoja de Simpson se produce porque el alto rendimiento en el conjunto de entrenamiento no se traduce en un alto rendimiento en el conjunto de prueba.
Falacia de McNamara|Confiar √∫nicamente en las m√©tricas en situaciones complejas y perder de vista el panorama general.|Un equipo de marketing de una empresa de productos de belleza se centra en mejorar la tasa de clics en sus anuncios en l√≠nea, pero pierden de vista el hecho de que la tasa de conversi√≥n en ventas sigue siendo baja. En lugar de centrarse en mejorar la calidad del producto o la experiencia del usuario en la web, siguen tratando de mejorar la tasa de clics como la √∫nica m√©trica importante.|Un equipo de ingenieros de una empresa de software desarrolla un algoritmo de inteligencia artificial para clasificar im√°genes. A medida que siguen entrenando el modelo, se dan cuenta de que la precisi√≥n en el conjunto de entrenamiento est√° mejorando constantemente, pero la precisi√≥n en un conjunto de datos diferente sigue siendo baja. Sin embargo, en lugar de revisar el modelo para ver si hay alg√∫n problema fundamental, siguen ajustando el modelo para que se ajuste mejor al conjunto de entrenamiento, lo que resulta en un modelo sobreajustado que no funciona bien en situaciones reales.
Sobreajuste|Crear un modelo que est√© demasiado adaptado a los datos que tienes y que no sea representativo de la tendencia general.|Se ajusta un modelo de predicci√≥n de ventas basado en datos hist√≥ricos de un solo producto, y se utiliza ese mismo modelo para predecir las ventas de otros productos sin tener en cuenta las diferencias en sus caracter√≠sticas o comportamientos de ventas.|Si se entrena un modelo de aprendizaje autom√°tico en un conjunto de datos espec√≠fico y se ajusta demasiado a ese conjunto de datos en particular, lo que hace que sea menos preciso al predecir nuevos datos que no estaban en el conjunto original.|
Sesgo de publicaci√≥n|Hallazgos interesantes de investigaci√≥n tienen m√°s probabilidades de ser publicados, distorsionando nuestra impresi√≥n de la realidad.|Una compa√±√≠a encarga un estudio para analizar el mercado y solo publica los resultados que respaldan su estrategia actual de negocio, mientras que omite aquellos resultados que sugieren un cambio en la estrategia.|Un equipo de investigaci√≥n publica solo los resultados positivos de un estudio sobre una nueva tecnolog√≠a, pero no publica los resultados negativos o aquellos que indican limitaciones importantes.|
Peligro de las m√©tricas de resumen|S√≥lo mirar las m√©tricas de resumen y perder grandes diferencias en los datos crudos.|Un gerente de ventas se enfoca en el n√∫mero total de ventas como su √∫nica m√©trica para evaluar el √©xito de su equipo de ventas, sin tener en cuenta otras m√©tricas importantes como la satisfacci√≥n del cliente o el n√∫mero de clientes nuevos adquiridos.|Un equipo de desarrollo de software se enfoca en la velocidad de entrega de nuevas caracter√≠sticas como su √∫nica m√©trica de rendimiento, sin tener en cuenta la calidad del c√≥digo, la escalabilidad y la capacidad de mantenimiento del software.
