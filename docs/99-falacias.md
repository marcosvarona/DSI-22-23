# Errores en los datos a evitar

Basado en el documento de [Geckoboard](https://www.geckoboard.com/assets/img/data_fallacies/Geckoboard-Data-Fallacies-Poster.pdf)

|||ADE|Ingeniería
-|-|-|-|
Cosecha selectiva (Cherry Picking)|Seleccionar resultados que se ajustan a tu afirmación y excluir aquellos que no lo hacen.|Un CEO de una empresa de tecnología selecciona solo los datos financieros positivos de su compañía para presentarlos a los inversores, omitiendo las métricas negativas.|Un ingeniero selecciona solo los datos de resistencia de los materiales que cumplen con las especificaciones, mientras ignora los datos que no cumplen con ellas, lo que puede llevar a una mala evaluación de la calidad del material.
Extracción de datos (Data Dredging)|Probar repetidamente nuevas hipótesis contra el mismo conjunto de datos, sin reconocer que la mayoría de las correlaciones serán resultado del azar.|
Sesgo de supervivencia (Survivorship Bias)|Sacar conclusiones de un conjunto incompleto de datos, porque esos datos han "sobrevivido" a ciertos criterios de selección.|Un inversor estudia solo las empresas que sobreviven en el mercado, ignorando aquellas que fracasaron, lo que puede llevar a una evaluación incorrecta del riesgo y la rentabilidad.|Un ingeniero estudia solo los diseños que fueron exitosos, ignorando los diseños que fracasaron, lo que puede llevar a una evaluación inadecuada de la fiabilidad y seguridad de los diseños.
Efecto cobra|Establecer un incentivo que produce accidentalmente el resultado opuesto al que se pretendía. También conocido como incentivo perverso.|Una empresa decide establecer un programa de incentivos basado en la cantidad de ventas de un determinado producto. Si los incentivos son mal diseñados y no tienen en cuenta otros factores relevantes, los vendedores pueden comenzar a enfocarse únicamente en el producto con incentivos, descuidando otros productos importantes y perjudicando a la empresa a largo plazo.|Un equipo de desarrollo de software que se fija una fecha límite muy estricta para el lanzamiento de un producto. Si el equipo se enfoca demasiado en cumplir con la fecha límite, podrían descuidar la calidad del software y lanzar un producto con errores y problemas de seguridad, lo que en última instancia dañaría la reputación de la empresa y afectaría su rentabilidad a largo plazo.|
Causalidad falsa|Asumir erróneamente que cuando dos eventos parecen estar relacionados, uno debe haber causado el otro.|Una empresa experimenta un aumento en sus ventas después de lanzar una campaña publicitaria en redes sociales y concluye que la campaña fue la única causa del aumento en las ventas, ignorando otros factores que podrían haber influido, como cambios en la demanda del mercado.|En un proyecto de desarrollo de software, se decide utilizar una nueva tecnología de base de datos y se observa una mejora en el rendimiento del sistema después de su implementación. Sin embargo, se ignora el hecho de que otras mejoras en el código del software también pueden haber contribuido al aumento del rendimiento, y se concluye que la nueva tecnología de base de datos fue la única causa del aumento.|
Manipulación electoral|Manipular los límites geográficos utilizados para agrupar datos con el fin de cambiar el resultado.
Sesgo de muestreo|Sacar conclusiones de un conjunto de datos que no es representativo de la población que se está intentando entender.|Si una empresa realiza una encuesta sobre la satisfacción del cliente y solo pregunta a los clientes que han tenido una experiencia positiva con la empresa, la muestra resultante puede ser sesgada hacia los clientes satisfechos, lo que lleva a una visión incompleta de la satisfacción general del cliente.|Una empresa de tecnología que solo contrata a graduados de universidades de élite para sus trabajos de ingeniería puede estar sesgada en su selección de candidatos y, por lo tanto, puede perder a personas altamente talentosas que no asistieron a esas universidades de élite.|
Falacia del jugador|Creer erróneamente que, debido a que algo ha sucedido con más frecuencia de lo habitual, es menos probable que suceda en el futuro (y viceversa).|Una empresa invierte en una nueva tecnología porque ha tenido éxito en el pasado. Sin embargo, el éxito pasado no garantiza el éxito futuro, y la empresa podría estar cometiendo la falacia del jugador al pensar que la nueva tecnología será exitosa solo porque sus tecnologías anteriores lo fueron.|Un equipo de desarrollo que cree que un software o sistema seguirá funcionando correctamente, incluso después de haber encontrado varios errores o fallos en versiones anteriores. Esta creencia puede llevar a una complacencia en la calidad del código y puede resultar en un sistema defectuoso.|
Efecto Hawthorne|El acto de monitorear a alguien puede afectar su comportamiento, lo que lleva a resultados falsos. También conocido como el efecto del observador.|Un gerente de producción decide realizar un experimento para medir la productividad de sus trabajadores. Durante un mes, coloca a un equipo de trabajo en una nueva línea de producción con un ambiente mejorado y monitorea su productividad. Sin embargo, los trabajadores notan la atención extra y comienzan a trabajar más duro de lo normal, lo que lleva a una mejora en la productividad. Al final del mes, el gerente concluye que la nueva línea de producción y el ambiente mejorado son la causa del aumento en la productividad, sin reconocer el efecto Hawthorne de la atención extra.|Un ingeniero de software está probando una nueva función en un programa y quiere medir la eficacia de la misma. Sin embargo, cuando se realiza la prueba, los usuarios del programa están más conscientes y más comprometidos en proporcionar retroalimentación. Debido a esto, la función parece ser más eficaz de lo que realmente es, y el ingeniero concluye erróneamente que la función es exitosa en términos de satisfacción del usuario, sin reconocer el efecto Hawthorne de la atención extra.|
Regresión hacia la media|Cuando algo sucede de manera inusualmente buena o mala, volverá a la media con el tiempo.|Un gerente de ventas observa que un vendedor ha tenido un mes excepcionalmente bueno en términos de ventas y decide darle un bono adicional para recompensarlo. Sin embargo, el mes siguiente las ventas del vendedor vuelven a ser más cercanas al promedio. Si el gerente esperaba que las ventas del vendedor fueran siempre excepcionales, podría haber caído en la falacia de regresión hacia la media.|Un equipo de ingenieros de software analiza el rendimiento de un algoritmo de clasificación de imágenes en un conjunto de datos de prueba y descubre que el algoritmo tiene una precisión del 100%. Los ingenieros deciden implementar el algoritmo en producción, pero descubren que su precisión disminuye significativamente en comparación con el conjunto de prueba. Este resultado podría ser un ejemplo de regresión hacia la media, ya que la precisión del conjunto de prueba era probablemente excepcionalmente alta debido a la selección de datos y no reflejaba el rendimiento real del algoritmo.|
Paradoja de Simpson|Cuando aparece una tendencia en diferentes subconjuntos de datos, pero desaparece o se invierte cuando los grupos se combinan.|Supongamos que una empresa está interesada en evaluar el rendimiento de sus vendedores en dos regiones diferentes. Al analizar los datos, se observa que en cada región, los vendedores que trabajan a tiempo completo venden más que los que trabajan a tiempo parcial. Sin embargo, al combinar los datos de ambas regiones, se descubre que los vendedores a tiempo parcial, en realidad, venden más que los de tiempo completo en general. Esta paradoja se produce porque la región con más vendedores a tiempo parcial tenía una demanda mayor de productos que la otra región.|Se está desarrollando un algoritmo de clasificación para reconocer caracteres escritos a mano en imágenes digitales. En una primera prueba, el algoritmo tiene un alto porcentaje de éxito al clasificar los caracteres de un conjunto de entrenamiento. Sin embargo, al probarlo con un conjunto de prueba diferente, el porcentaje de éxito se reduce drásticamente. Esto puede deberse a que el algoritmo se ha ajustado demasiado a los datos de entrenamiento, perdiendo su capacidad para clasificar correctamente los datos de prueba. En este caso, la paradoja de Simpson se produce porque el alto rendimiento en el conjunto de entrenamiento no se traduce en un alto rendimiento en el conjunto de prueba.
Falacia de McNamara|Confiar únicamente en las métricas en situaciones complejas y perder de vista el panorama general.|Un equipo de marketing de una empresa de productos de belleza se centra en mejorar la tasa de clics en sus anuncios en línea, pero pierden de vista el hecho de que la tasa de conversión en ventas sigue siendo baja. En lugar de centrarse en mejorar la calidad del producto o la experiencia del usuario en la web, siguen tratando de mejorar la tasa de clics como la única métrica importante.|Un equipo de ingenieros de una empresa de software desarrolla un algoritmo de inteligencia artificial para clasificar imágenes. A medida que siguen entrenando el modelo, se dan cuenta de que la precisión en el conjunto de entrenamiento está mejorando constantemente, pero la precisión en un conjunto de datos diferente sigue siendo baja. Sin embargo, en lugar de revisar el modelo para ver si hay algún problema fundamental, siguen ajustando el modelo para que se ajuste mejor al conjunto de entrenamiento, lo que resulta en un modelo sobreajustado que no funciona bien en situaciones reales.
Sobreajuste|Crear un modelo que esté demasiado adaptado a los datos que tienes y que no sea representativo de la tendencia general.|Se ajusta un modelo de predicción de ventas basado en datos históricos de un solo producto, y se utiliza ese mismo modelo para predecir las ventas de otros productos sin tener en cuenta las diferencias en sus características o comportamientos de ventas.|Si se entrena un modelo de aprendizaje automático en un conjunto de datos específico y se ajusta demasiado a ese conjunto de datos en particular, lo que hace que sea menos preciso al predecir nuevos datos que no estaban en el conjunto original.|
Sesgo de publicación|Hallazgos interesantes de investigación tienen más probabilidades de ser publicados, distorsionando nuestra impresión de la realidad.|Una compañía encarga un estudio para analizar el mercado y solo publica los resultados que respaldan su estrategia actual de negocio, mientras que omite aquellos resultados que sugieren un cambio en la estrategia.|Un equipo de investigación publica solo los resultados positivos de un estudio sobre una nueva tecnología, pero no publica los resultados negativos o aquellos que indican limitaciones importantes.|
Peligro de las métricas de resumen|Sólo mirar las métricas de resumen y perder grandes diferencias en los datos crudos.|Un gerente de ventas se enfoca en el número total de ventas como su única métrica para evaluar el éxito de su equipo de ventas, sin tener en cuenta otras métricas importantes como la satisfacción del cliente o el número de clientes nuevos adquiridos.|Un equipo de desarrollo de software se enfoca en la velocidad de entrega de nuevas características como su única métrica de rendimiento, sin tener en cuenta la calidad del código, la escalabilidad y la capacidad de mantenimiento del software.
